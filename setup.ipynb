{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import py7zr\n",
    "# from pathlib import Path\n",
    "\n",
    "# # extract compressed data file\n",
    "# data_path = Path('data')\n",
    "# with py7zr.SevenZipFile(data_path.joinpath('data_dirty.7z'), mode='r') as z:\n",
    "#     z.extractall(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfaidx import Fasta\n",
    "data = Fasta(\"data/15400-16555_sequence.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1732"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1732"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "for record in data:\n",
    "    count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1732\n",
      "15893.848729792147\n",
      "512.1947490467297\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_seq = len(data.keys())\n",
    "seq_len = np.array([len(x[:].seq) for x in data])\n",
    "plt.hist(seq_len)\n",
    "plt.show()\n",
    "\n",
    "print(num_seq)\n",
    "print(np.mean(seq_len))\n",
    "print(np.std(seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_kmers(sequence, ksize):\n",
    "    kmers = []\n",
    "    n_kmers = len(sequence) - ksize + 1\n",
    "\n",
    "    for i in range(n_kmers):\n",
    "        kmer = sequence[i:i + ksize]\n",
    "        kmers.append(kmer)\n",
    "\n",
    "    return kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16535</th>\n",
       "      <th>16536</th>\n",
       "      <th>16537</th>\n",
       "      <th>16538</th>\n",
       "      <th>16539</th>\n",
       "      <th>16540</th>\n",
       "      <th>16541</th>\n",
       "      <th>16542</th>\n",
       "      <th>16543</th>\n",
       "      <th>16544</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTAACCACTCA</td>\n",
       "      <td>TAACCACTCAC</td>\n",
       "      <td>AACCACTCACG</td>\n",
       "      <td>ACCACTCACGG</td>\n",
       "      <td>CCACTCACGGG</td>\n",
       "      <td>CACTCACGGGA</td>\n",
       "      <td>ACTCACGGGAG</td>\n",
       "      <td>CTCACGGGAGC</td>\n",
       "      <td>TCACGGGAGCT</td>\n",
       "      <td>CACGGGAGCTC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CACCCTATTAA</td>\n",
       "      <td>ACCCTATTAAC</td>\n",
       "      <td>CCCTATTAACC</td>\n",
       "      <td>CCTATTAACCA</td>\n",
       "      <td>CTATTAACCAC</td>\n",
       "      <td>TATTAACCACT</td>\n",
       "      <td>ATTAACCACTC</td>\n",
       "      <td>TTAACCACTCA</td>\n",
       "      <td>TAACCACTCAC</td>\n",
       "      <td>AACCACTCACG</td>\n",
       "      <td>...</td>\n",
       "      <td>TTAAATAAGAC</td>\n",
       "      <td>TAAATAAGACA</td>\n",
       "      <td>AAATAAGACAT</td>\n",
       "      <td>AATAAGACATC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCACAGGTCTA</td>\n",
       "      <td>CACAGGTCTAT</td>\n",
       "      <td>ACAGGTCTATC</td>\n",
       "      <td>CAGGTCTATCA</td>\n",
       "      <td>AGGTCTATCAC</td>\n",
       "      <td>GGTCTATCACC</td>\n",
       "      <td>GTCTATCACCC</td>\n",
       "      <td>TCTATCACCCT</td>\n",
       "      <td>CTATCACCCTA</td>\n",
       "      <td>TATCACCCTAT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 16545 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0            1            2            3            4      \\\n",
       "0  TTAACCACTCA  TAACCACTCAC  AACCACTCACG  ACCACTCACGG  CCACTCACGGG   \n",
       "1  CACCCTATTAA  ACCCTATTAAC  CCCTATTAACC  CCTATTAACCA  CTATTAACCAC   \n",
       "2  TCACAGGTCTA  CACAGGTCTAT  ACAGGTCTATC  CAGGTCTATCA  AGGTCTATCAC   \n",
       "\n",
       "         5            6            7            8            9      ...  \\\n",
       "0  CACTCACGGGA  ACTCACGGGAG  CTCACGGGAGC  TCACGGGAGCT  CACGGGAGCTC  ...   \n",
       "1  TATTAACCACT  ATTAACCACTC  TTAACCACTCA  TAACCACTCAC  AACCACTCACG  ...   \n",
       "2  GGTCTATCACC  GTCTATCACCC  TCTATCACCCT  CTATCACCCTA  TATCACCCTAT  ...   \n",
       "\n",
       "         16535        16536        16537        16538 16539 16540 16541 16542  \\\n",
       "0          NaN          NaN          NaN          NaN   NaN   NaN   NaN   NaN   \n",
       "1  TTAAATAAGAC  TAAATAAGACA  AAATAAGACAT  AATAAGACATC   NaN   NaN   NaN   NaN   \n",
       "2          NaN          NaN          NaN          NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "  16543 16544  \n",
       "0   NaN   NaN  \n",
       "1   NaN   NaN  \n",
       "2   NaN   NaN  \n",
       "\n",
       "[3 rows x 16545 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksize = 11\n",
    "corpus = pd.DataFrame([build_kmers(x[:].seq, ksize) for x in data])\n",
    "corpus = corpus.fillna(np.NaN)\n",
    "corpus = corpus.iloc[:3,:]\n",
    "corpus\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17191"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab, index = {}, 1  # start indexing from 1\n",
    "vocab['<pad>'] = 0  # add a padding token\n",
    "for _, sentence in corpus.iterrows():\n",
    "  for token in sentence.values:\n",
    "    if token not in vocab:\n",
    "      vocab[token] = index\n",
    "      index += 1\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_vocab = {index: token for token, index in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sequence = [[vocab[word] for word in corpus.iloc[sent,:]] for sent in range(corpus.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target and context words for one positive skip-gram.\n",
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "# Set the number of negative samples per positive context.\n",
    "num_ns = 4\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class,  # class that should be sampled as 'positive'\n",
    "    num_true=1,  # each positive skip-gram has 1 positive context class\n",
    "    num_sampled=num_ns,  # number of negative context words to sample\n",
    "    unique=True,  # all the negative samples should be unique\n",
    "    range_max=vocab_size,  # pick index of the samples from [0, vocab_size]\n",
    "    seed=SEED,  # seed for reproducibility\n",
    "    name=\"negative_sampling\"  # name of this operation\n",
    ")\n",
    "print(negative_sampling_candidates)\n",
    "print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
    "# (int-encoded sentences) based on window size, number of negative samples\n",
    "# and vocabulary size.\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "  # Elements of each training example are appended to these lists.\n",
    "  targets, contexts, labels = [], [], []\n",
    "\n",
    "  # Build the sampling table for vocab_size tokens.\n",
    "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "  # Iterate over all sequences (sentences) in dataset.\n",
    "  for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "          sequence,\n",
    "          vocabulary_size=vocab_size,\n",
    "          sampling_table=sampling_table,\n",
    "          window_size=window_size,\n",
    "          negative_samples=0)\n",
    "\n",
    "    # Iterate over each positive skip-gram pair to produce training examples\n",
    "    # with positive context word and negative samples.\n",
    "    for target_word, context_word in positive_skip_grams:\n",
    "      context_class = tf.expand_dims(\n",
    "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "          true_classes=context_class,\n",
    "          num_true=1,\n",
    "          num_sampled=num_ns,\n",
    "          unique=True,\n",
    "          range_max=vocab_size,\n",
    "          seed=SEED,\n",
    "          name=\"negative_sampling\")\n",
    "\n",
    "      # Build context and label vectors (for one target word)\n",
    "      negative_sampling_candidates = tf.expand_dims(\n",
    "          negative_sampling_candidates, 1)\n",
    "\n",
    "      context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "\n",
    "      # Append each element from the training example to global lists.\n",
    "      targets.append(target_word)\n",
    "      contexts.append(context)\n",
    "      labels.append(label)\n",
    "\n",
    "  return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]2021-10-28 23:35:00.072990: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "100%|██████████| 3/3 [00:13<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "targets.shape: (155417,)\n",
      "contexts.shape: (155417, 5)\n",
      "labels.shape: (155417, 5)\n"
     ]
    }
   ],
   "source": [
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=example_sequence,\n",
    "    window_size=2,\n",
    "    num_ns=4,\n",
    "    vocab_size=vocab_size,\n",
    "    seed=SEED)\n",
    "\n",
    "targets = np.array(targets)\n",
    "contexts = np.array(contexts)[:,:,0]\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"targets.shape: {targets.shape}\")\n",
    "print(f\"contexts.shape: {contexts.shape}\")\n",
    "print(f\"labels.shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (((1024,), (1024, 5)), (1024, 5)), types: ((tf.int64, tf.int64), tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: (((1024,), (1024, 5)), (1024, 5)), types: ((tf.int64, tf.int64), tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(dataset)\n",
    "num_ns = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim):\n",
    "    super(Word2Vec, self).__init__()\n",
    "    self.target_embedding = layers.Embedding(vocab_size,\n",
    "                                      embedding_dim,\n",
    "                                      input_length=1,\n",
    "                                      name=\"w2v_embedding\")\n",
    "    self.context_embedding = layers.Embedding(vocab_size,\n",
    "                                       embedding_dim,\n",
    "                                       input_length=num_ns+1)\n",
    "\n",
    "  def call(self, pair):\n",
    "    target, context = pair\n",
    "    # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n",
    "    # context: (batch, context)\n",
    "    if len(target.shape) == 2:\n",
    "      target = tf.squeeze(target, axis=1)\n",
    "    # target: (batch,)\n",
    "    word_emb = self.target_embedding(target)\n",
    "    # word_emb: (batch, embed)\n",
    "    context_emb = self.context_embedding(context)\n",
    "    # context_emb: (batch, context, embed)\n",
    "    dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
    "    # dots: (batch, context)\n",
    "    return dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  2/151 [..............................] - ETA: 7s - loss: 1.6093 - accuracy: 0.2056  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 23:37:18.064562: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-28 23:37:18.164210: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-10-28 23:37:18.164256: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-10-28 23:37:18.206684: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-10-28 23:37:18.215303: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-10-28 23:37:18.230955: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/train/plugins/profile/2021_10_28_23_37_18\n",
      "\n",
      "2021-10-28 23:37:18.247566: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/train/plugins/profile/2021_10_28_23_37_18/tinkercliffs1.trace.json.gz\n",
      "2021-10-28 23:37:18.252677: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/train/plugins/profile/2021_10_28_23_37_18\n",
      "\n",
      "2021-10-28 23:37:18.255428: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/train/plugins/profile/2021_10_28_23_37_18/tinkercliffs1.memory_profile.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/151 [..............................] - ETA: 9s - loss: 1.6095 - accuracy: 0.1998 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 23:37:18.287346: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/train/plugins/profile/2021_10_28_23_37_18\n",
      "Dumped tool data for xplane.pb to logs/train/plugins/profile/2021_10_28_23_37_18/tinkercliffs1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/train/plugins/profile/2021_10_28_23_37_18/tinkercliffs1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/train/plugins/profile/2021_10_28_23_37_18/tinkercliffs1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/train/plugins/profile/2021_10_28_23_37_18/tinkercliffs1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/train/plugins/profile/2021_10_28_23_37_18/tinkercliffs1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 10s 66ms/step - loss: 1.5889 - accuracy: 0.6192\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 11s 71ms/step - loss: 1.3079 - accuracy: 0.9855\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 11s 72ms/step - loss: 0.7145 - accuracy: 0.9467\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 11s 73ms/step - loss: 0.4337 - accuracy: 0.9402\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.3060 - accuracy: 0.9601\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.2221 - accuracy: 0.9790\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.1613 - accuracy: 0.9906\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.1171 - accuracy: 0.9964\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.0856 - accuracy: 0.9990\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 10s 68ms/step - loss: 0.0632 - accuracy: 0.9997\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.0474 - accuracy: 0.9999\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.0362 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 9s 63ms/step - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 10s 63ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 10s 63ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 9s 62ms/step - loss: 0.0072 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aaf01ca8ac0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (((1024,), (1024, 5)), (1024, 5)), types: ((tf.int64, tf.int64), tf.int64)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "# vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17191, 128)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17191"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  if word is np.NaN:\n",
    "    continue\n",
    "  vec = weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b375a0474f650c25ecb1f5b23c0753c2b5e7495196431cccebd57e94755f51a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('CS5604-proj': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
